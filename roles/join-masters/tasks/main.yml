- name: Read control plane join command from file
  slurp:
    src: /root/kubeadm_join_controlplane_command.txt
  register: join_command_file
  delegate_to: k8s-master-1

- name: Set join command fact
  set_fact:
    join_command_controlplane: "{{ join_command_file.content | b64decode | trim }}"

- name: Check if additional master nodes are already joined
  shell: /usr/local/bin/kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes | grep -c "master\|control-plane" || true
  register: master_nodes_count
  delegate_to: k8s-master-1

- name: Display current master nodes count
  debug:
    msg: "Current master nodes count: {{ master_nodes_count.stdout }}"
  delegate_to: k8s-master-1

- name: Install socat package (required for kubeadm join)
  apt:
    name: socat
    state: present
  when: inventory_hostname != 'k8s-master-1'

- name: Check if node is already joined as worker
  shell: /usr/local/bin/kubectl --kubeconfig=/etc/kubernetes/admin.conf get node {{ inventory_hostname }} -o jsonpath='{.metadata.labels.node-role\.kubernetes\.io/control-plane}' 2>/dev/null || echo "not-found"
  register: node_role_check
  delegate_to: k8s-master-1
  when: 
    - inventory_hostname != 'k8s-master-1'
    - inventory_hostname in groups['k8s_master']
  failed_when: false

- name: Reset node if it joined as worker instead of control-plane
  shell: kubeadm reset -f
  when: 
    - inventory_hostname != 'k8s-master-1'
    - inventory_hostname in groups['k8s_master']
    - node_role_check.stdout == ""
  
- name: Remove node from cluster if it needs to be reset
  shell: /usr/local/bin/kubectl --kubeconfig=/etc/kubernetes/admin.conf delete node {{ inventory_hostname }}
  delegate_to: k8s-master-1
  when: 
    - inventory_hostname != 'k8s-master-1'
    - inventory_hostname in groups['k8s_master']
    - node_role_check.stdout == ""
  failed_when: false

- name: First attempt to join additional control plane nodes
  shell: "{{ join_command_controlplane }}"
  register: join_controlplane_output_first
  when: inventory_hostname != 'k8s-master-1'
  failed_when: false

- name: Check if join failed due to expired certificates
  set_fact:
    cert_expired: "{{ 'cipher: message authentication failed' in join_controlplane_output_first.stderr or 'kubeadm-certs' in join_controlplane_output_first.stderr and 'not found' in join_controlplane_output_first.stderr }}"
  when: 
    - inventory_hostname != 'k8s-master-1'
    - join_controlplane_output_first is defined
    - join_controlplane_output_first.rc != 0

- name: Generate fresh certificates and join command if expired
  block:
    - name: Upload fresh certificates
      shell: kubeadm init phase upload-certs --upload-certs
      register: cert_upload
      delegate_to: k8s-master-1

    - name: Extract certificate key
      set_fact:
        fresh_cert_key: "{{ cert_upload.stdout_lines[-1] }}"
      delegate_to: k8s-master-1

    - name: Generate fresh control plane join command
      shell: kubeadm token create --print-join-command --certificate-key {{ fresh_cert_key }}
      register: fresh_join_command
      delegate_to: k8s-master-1

    - name: Save fresh join command
      copy:
        content: "{{ fresh_join_command.stdout }}"
        dest: /root/kubeadm_join_controlplane_command.txt
        mode: '0644'
      delegate_to: k8s-master-1

    - name: Set fresh join command fact
      set_fact:
        join_command_controlplane: "{{ fresh_join_command.stdout }}"

  when: 
    - cert_expired is defined 
    - cert_expired | bool
    - inventory_hostname != 'k8s-master-1'
  run_once: true

- name: Second attempt to join control plane nodes with fresh certificates
  shell: "{{ join_command_controlplane }}"
  register: join_controlplane_output
  when: 
    - inventory_hostname != 'k8s-master-1'
    - cert_expired is defined 
    - cert_expired | bool
  failed_when: 
    - join_controlplane_output.rc != 0
    - "'already exists' not in join_controlplane_output.stderr"

- name: Use first attempt result if certificates were not expired
  set_fact:
    join_controlplane_output: "{{ join_controlplane_output_first }}"
  when: 
    - inventory_hostname != 'k8s-master-1'
    - cert_expired is not defined or not (cert_expired | bool)
    - join_controlplane_output_first.rc == 0

- name: Display join output for additional masters
  debug:
    var: join_controlplane_output
  when: 
    - inventory_hostname != 'k8s-master-1'
    - join_controlplane_output is defined

- name: Wait for all nodes to be ready
  shell: /usr/local/bin/kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes --no-headers | grep -v "Ready" | wc -l
  register: nodes_not_ready
  until: nodes_not_ready.stdout == "0"
  retries: 30
  delay: 10
  delegate_to: k8s-master-1

- name: Display all nodes status
  shell: /usr/local/bin/kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes -o wide
  register: all_nodes_status
  delegate_to: k8s-master-1

- name: Show final cluster status
  debug:
    var: all_nodes_status.stdout
  delegate_to: k8s-master-1

- name: Label additional master nodes as control-plane
  shell: /usr/local/bin/kubectl --kubeconfig=/etc/kubernetes/admin.conf label node {{ inventory_hostname }} node-role.kubernetes.io/control-plane= --overwrite
  register: label_result
  delegate_to: k8s-master-1
  when: inventory_hostname != 'k8s-master-1'
  failed_when: false

- name: Display labeling results
  debug:
    msg: "Node {{ inventory_hostname }} labeled as control-plane: {{ label_result.stdout }}"
  when: 
    - inventory_hostname != 'k8s-master-1'
    - label_result is defined

- name: Verify all nodes have control-plane role
  shell: /usr/local/bin/kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes
  register: final_nodes_status
  delegate_to: k8s-master-1

- name: Show final cluster status with roles
  debug:
    var: final_nodes_status.stdout
  delegate_to: k8s-master-1